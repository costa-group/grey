#!/usr/bin/env python3
import itertools
import json
import logging
import resource
import sys
import os
from typing import List, Dict, Tuple, Any, Set, Optional, Generator
from collections import defaultdict, Counter
import traceback
from enum import Enum, unique

import networkx
import networkx as nx
# from analysis.greedy_validation import check_execution_from_ids
from global_params.types import var_id_T, instr_id_T, instr_JSON_T, SMS_T

# Specific type to identify which positions corresponds to the ones
# in the current and final stacks
cstack_pos_T = int
fstack_pos_T = int

# Annotation for the maximum stack depth that can be managed through operations
STACK_DEPTH = 16


def _simplify_graph_to_selected_nodes(graph: nx.DiGraph, selected_nodes: List) -> nx.DiGraph:
    """
    Auxiliary method that returns the transitive reduction of the graph that is generated by
    preserving the initial paths in the original path when restricted to the selected nodes
    """
    subgraph = nx.DiGraph()
    subgraph.add_nodes_from(selected_nodes)

    # Add edges based on reachability using BFS/DFS
    for u in selected_nodes:
        for v in selected_nodes:
            # Avoid self-loops and skips relations that have already been considered
            if u != v and not subgraph.has_edge(v, u):

                # Check if v is reachable from u in G using DFS
                reachable = nx.algorithms.dfs_predecessors(graph, source=u)
                if v in reachable:
                    subgraph.add_edge(u, v)

    # Step 4: Apply transitive reduction on the dynamically created subgraph
    subgraph_reduced = nx.transitive_reduction(subgraph)
    return subgraph_reduced


def idx_wrt_cstack(idx: fstack_pos_T, cstack: List, fstack: List) -> cstack_pos_T:
    """
    Given a position w.r.t fstack, returns the corresponding position w.r.t cstack
    """
    return idx - len(fstack) + len(cstack)


def idx_wrt_fstack(idx: cstack_pos_T, cstack: List, fstack: List) -> fstack_pos_T:
    """
    Given a position w.r.t cstack, returns the corresponding position w.r.t fstack
    """
    return idx - len(cstack) + len(fstack)


def top_relative_position_to_fstack(cstack: List[var_id_T], fstack: List[var_id_T]) -> int:
    return idx_wrt_fstack(0, cstack, fstack)


def extract_idx_from_id(instr_id: str) -> int:
    return int(instr_id.split('_')[-1])


def cheap(instr: instr_JSON_T) -> bool:
    """
    Cheap computations are those who take one instruction (i.e. inpt_sk is empty)
    """
    return len(instr['inpt_sk']) == 0 and instr["size"] <= 2


class SymbolicState:
    """
    A symbolic state includes a stack, a dict indicating the number of total uses of each instruction,
    the instructions that can be computed and the variables that must be duplicated
    """

    def __init__(self, initial_stack: List[var_id_T], dependency_graph: nx.DiGraph,
                 stack_var_copies_needed: Dict[var_id_T, int], user_instrs: List[instr_JSON_T]) -> None:
        self.debug_mode = True

        self.stack: List[var_id_T] = initial_stack.copy()

        # The dependency graph with the instructions that can be computed due to
        # its arguments are already computed
        self.dep_graph = dependency_graph.copy()

        # Terms that are cheap to compute
        self.cheap_terms_to_compute = {output_var for instr in user_instrs if cheap(instr)
                                       for output_var in instr["outpt_sk"]}

        self.variables_to_dup = {stack_var for stack_var in initial_stack if stack_var_copies_needed[stack_var] > 0}

        self.stack_var_copies_needed = stack_var_copies_needed.copy()

    def swap(self, x: int) -> List[instr_id_T]:
        """
        Stores the top of the stack in the local with index x. in_position marks whether the element is
        solved in flocals
        """
        assert 0 <= x < len(self.stack), f"Swapping with index {x} a stack of {len(self.stack)} elements: {self.stack}"
        self.stack[0], self.stack[x] = self.stack[x], self.stack[0]

        # Var copies: no modification, as we are just moving two elements
        return [f"SWAP{x}"]

    def dup(self, x: int) -> List[instr_id_T]:
        """
        Tee instruction in local with index x. in_position marks whether the element is solved in flocals
        """
        idx = x - 1
        assert 0 <= idx < len(self.stack), \
            f"Duplicating index {x} in a stack in {len(self.stack)} elements: {self.stack}"
        self.stack.insert(0, self.stack[idx])

        # Var copies: we increment the element that we have duplicated
        self.stack_var_copies_needed[self.stack[0]] -= 1
        return [f"DUP{x}"]

    def pop(self) -> List[instr_id_T]:
        """
        Drops the last element
        """
        stack_var = self.stack.pop(0)

        # Var copies: we add one because the stack var is totally removed from the encoding
        self.stack_var_copies_needed[stack_var] += 1
        return ["POP"]

    def uf(self, instr: instr_JSON_T) -> List[instr_id_T]:
        """
        Symbolic execution of instruction instr. Additionally, checks the arguments match if debug mode flag is enabled
        """
        consumed_elements = [self.stack.pop(0) for _ in range(len(instr['inpt_sk']))]

        # Neither liveness nor var uses are affected by consuming elements, as these elements are just being embedded
        # into a new term
        # Debug mode to check the pop args from the stack match
        if self.debug_mode:
            if instr['commutative']:
                # Compare them as multisets
                assert Counter(consumed_elements) == Counter(instr['inpt_sk']), \
                    f"{instr['id']} is not consuming the correct elements from the stack"
            else:
                # Compare them as lists
                assert consumed_elements == instr['inpt_sk'], \
                    f"{instr['id']} is not consuming the correct elements from the stack.\n" \
                    f"Consumed elements: {consumed_elements}\nRequired elements: {instr['inpt_sk']}"

        # We introduce the new elements
        for output_var in instr['outpt_sk']:
            self.stack.insert(0, output_var)
            # Var copies: increase one for each generated stack var
            self.stack_var_copies_needed[output_var] += 1

            # First case: cheap instructions just require to remove the element from the cheap instructions
            # if we have computed the necessary number of copies
            if cheap(instr):
                if self.stack_var_copies_needed[output_var] == 0:
                    self.cheap_terms_to_compute.remove(output_var)
            else:
                # Second case: we add the produced terms that need to be
                # duplicated to the corresponding list
                if self.stack_var_copies_needed[output_var] > 0:
                    self.variables_to_dup.add(output_var)

        if not cheap(instr):
            self.dep_graph.remove_node(instr["id"])

        return [instr["id"]]

    def from_memory(self, var_elem: var_id_T) -> List[instr_id_T]:
        """
        Assumes the value is retrieved from memory
        """
        self.stack.insert(0, var_elem)

        # Var uses: increase one for the variable
        self.stack_var_copies_needed[var_elem] += 1

        return [f"MEM({var_elem})"]

    def top_stack(self) -> Optional[var_id_T]:
        return None if len(self.stack) == 0 else self.stack[0]

    def is_accessible_swap(self, var_elem: var_id_T) -> bool:
        """
        Checks whether the variable element can be accessed for a swap instruction
        """
        return self.stack.index(var_elem) <= STACK_DEPTH

    def is_accessible_dup(self, var_elem: var_id_T) -> bool:
        """
        Checks whether the variable element can be accessed for a dup instruction
        """
        return self.stack.index(var_elem) < STACK_DEPTH

    def first_occurrence(self, var_elem: var_id_T) -> int:
        """
        Returns the first position in which the element appears
        """
        try:
            return self.stack.index(var_elem)
        except:
            return -1

    def last_accessible_occurrence(self, var_elem: var_id_T) -> int:
        """
        Returns the first position in which the element appears
        """
        try:
            return self.stack.index(var_elem)
        except:
            return -1

    def has_computations(self):
        """
        Checks if the current state has still computations left to do
        """
        # TODO: remove elements once they have 0 copies left and just check length
        return any(value > 0 for value in self.stack_var_copies_needed.values())

    def candidates(self) -> Tuple[List[instr_id_T], Set[var_id_T], Set[var_id_T]]:
        """
        Returns the possible candidates from the pool of available instructions, cheap instructions
        and stack variables that are needed to be duplicated
        """
        return [id_ for id_ in self.dep_graph.nodes if self.dep_graph.out_degree(id_) == 0], \
            self.cheap_terms_to_compute, self.variables_to_dup

    def __repr__(self):
        return str(self.stack)


class SMSgreedy:

    def __init__(self, json_format: SMS_T):
        self.debug_mode: bool = True
        # How many elements are placed in the correct position and cannot be moved further in a computation
        self.fixed_elements: int = 0
        self._user_instr: List[instr_JSON_T] = json_format['user_instrs']
        self._initial_stack: List[var_id_T] = json_format['src_ws']
        self._final_stack: List[var_id_T] = json_format['tgt_ws']
        self._deps: List[Tuple[var_id_T, var_id_T]] = json_format['dependencies']
        self.debug_logger = DebugLogger()

        # Note: we assume function invocations might have several variables in 'outpt_sk'
        self._var2instr = {var: ins for ins in self._user_instr for var in ins['outpt_sk']}
        self._id2instr = {ins['id']: ins for ins in self._user_instr}
        self._var2id = {var: ins['id'] for ins in self._user_instr for var in ins['outpt_sk']}
        self._var2pos_stack = self._compute_var2pos(self._final_stack)

        self._stack_var_copies_needed = self._compute_var_total_uses()
        self._dep_graph = self._compute_dependency_graph()

        # We determine which elements must be computed in order to compute certain instruction
        self._values_used = {}

        # Determine which topmost elements can be reused in the graph
        self._top_can_be_used = {}

        for instr in self._user_instr:
            self._compute_values_used(instr, self._values_used)
            self._compute_top_can_used(instr, self._top_can_be_used)

    def _compute_var_total_uses(self) -> Dict[var_id_T, int]:
        """
        Computes how many times each var must be computed due to appearing either in the final stack or as a subterm
        for other terms. It can be negative for terms that must be popped
        """
        var_uses = defaultdict(lambda: 0)

        for var_stack in self._initial_stack:
            var_uses[var_stack] -= 1

        # Count vars in the final stack
        for var_stack in self._final_stack:
            var_uses[var_stack] += 1

        # Count vars as input of other instrs
        for instr_id, instr in self._id2instr.items():
            for subterm_var in instr['inpt_sk']:
                var_uses[subterm_var] += 1

        return var_uses


    def _compute_var2pos(self, var_list: List[var_id_T]) -> Dict[var_id_T, List[int]]:
        """
        Dict that links each stack variable that appears in a var list to the
        list of positions it occupies
        """
        var2pos = defaultdict(lambda: [])

        for i, stack_var in enumerate(var_list):
            var2pos[stack_var].append(i)

        return var2pos

    def _compute_dependency_graph(self) -> nx.DiGraph:
        """
        We generate two dependency graphs: one for direct relations (i.e. one term embedded into another)
        and other with the dependencies due to memory/storage accesses
        """
        graph = nx.DiGraph()

        for instr in self._user_instr:
            instr_id = instr['id']
            graph.add_node(instr_id)

            for stack_elem in instr['inpt_sk']:
                # This means the stack element corresponds to another uninterpreted instruction
                associated_instr = self._var2instr.get(stack_elem, None)
                if associated_instr and not cheap(associated_instr):
                    graph.add_edge(instr_id, self._var2id[stack_elem])

        # We need to consider also the order given by the tuples
        for id1, id2 in self._deps:
            graph.add_edge(id2, id1)

        return graph

    def _compute_top_can_used(self, instr: instr_JSON_T, top_can_be_used: Dict[var_id_T, Set[var_id_T]]) -> Set[
        var_id_T]:
        """
        Computes for each instruction if the topmost element of the stack can be reused directly
        at some point. It considers commutative operations
        """
        reused_elements = top_can_be_used.get(instr["id"], None)
        if reused_elements is not None:
            return reused_elements

        current_uses = set()
        comm = instr["commutative"]
        first_element = True
        for stack_var in reversed(instr["inpt_sk"]):
            # We only consider the first element if the operation is not commutative, or both elements otherwise
            if comm or first_element:
                instr_bef = self._var2instr.get(stack_var, None)
                if instr_bef is not None:
                    instr_bef_id = instr_bef["id"]
                    if instr_bef_id not in top_can_be_used:
                        current_uses.update(self._compute_top_can_used(instr_bef, top_can_be_used))
                    else:
                        current_uses.update(top_can_be_used[instr_bef_id])
                    # Add only instructions that are relevant to our context
                    current_uses.add(stack_var)
            else:
                break
            first_element = False

        top_can_be_used[instr["id"]] = current_uses
        return current_uses

    def _compute_values_used(self, instr: instr_JSON_T, value_uses: Dict[var_id_T, List[var_id_T]]) -> List[var_id_T]:
        """
        For a given instruction, determines which stack elements must be computed in inorder
        """
        values_used = value_uses.get(instr["id"], None)
        if values_used is not None:
            return values_used

        current_uses = []
        for stack_var in instr["inpt_sk"]:
            instr_bef = self._var2instr.get(stack_var, None)
            if instr_bef is not None:
                instr_bef_id = instr_bef["id"]
                if instr_bef_id not in value_uses:
                    current_uses.extend(self._compute_values_used(instr_bef, value_uses))
                else:
                    current_uses.extend(value_uses[instr_bef_id])

            current_uses.append(stack_var)

        value_uses[instr["id"]] = current_uses
        return current_uses

    def greedy(self) -> List[instr_id_T]:
        """
        Main implementation of the greedy algorithm (i.e. the instruction scheduling algorithm)
        """
        cstate: SymbolicState = SymbolicState(self._initial_stack, self._dep_graph, self._stack_var_copies_needed,
                                              self._user_instr)
        optg = []

        self.debug_logger.debug_initial(cstate.dep_graph.nodes)

        # For easier code, we end the while when we need to choose an
        # operation and there are no operations left
        while True:
            var_top = cstate.top_stack()
            self.fixed_elements = 0

            self.debug_logger.debug_loop(cstate.dep_graph, optg, cstate)

            # Case 1: Top of the stack must be removed, as it appears more time it is being used
            if var_top is not None and cstate.stack_var_copies_needed < 0:
                self.debug_logger.debug_pop(var_top, cstate)
                optg.extend(cstate.pop())

            # Case 2: Top of the stack must be placed in some other position
            elif var_top is not None and (move_information := self.var_must_be_moved(var_top, cstate)) \
                    and move_information[0]:
                self.debug_logger.debug_move_var(var_top, move_information[1], cstate)
                optg.extend(cstate.swap(move_information[1]))

            # Case 3: Top of the stack cannot be moved to the corresponding position.
            # Hence, we just generate the following computation
            else:
                # There are no operations left to choose, so we stop the search
                if cstate.has_computations:
                    break

                next_id = self.choose_next_computation(cstate)
                next_instr = self._id2instr[next_id]
                self.debug_logger.debug_choose_computation(next_id, cstate)

                terms_to_dup = self._identify_subterms_to_dup(next_instr, cstate)
                self.debug_logger.debug_terms_to_dup(terms_to_dup)

                ops = self.compute_instr(next_instr, cstate, terms_to_dup)

                optg.extend(ops)

        optg.extend(self.solve_permutation(cstate))
        self.debug_logger.debug_after_permutation(cstate, optg)

        return optg

    def _available_positions(self, var_elem: var_id_T, cstate: SymbolicState) -> Generator[cstack_pos_T, None, None]:
        """
        Generator for the set of available positions in cstack where the var element can be placed
        """
        # We just need to check that the positions in which the element appears in the
        # final stack are in range and not contain the element
        for position in reversed(self._var2pos_stack[var_elem]):
            fidx = idx_wrt_cstack(position, cstate.stack, self._final_stack)

            # When the index is negative, it means there are not enough elements in cstack
            # to place the corresponding element
            if fidx < 0:
                break

            # A variable must be moved when a positive index is found (less than STACK_DEPTH)
            # which does not contain yet the corresponding element
            elif STACK_DEPTH >= fidx >= 0 and fidx < len(cstate.stack) and cstate.stack[fidx] != var_elem:
                yield fidx

    def _deepest_position(self, var_elem: var_id_T) -> Optional[int]:
        """
        Deepest position in the final stack of var_elem (if any). Used to determine which computation is chosen first
        """
        return self._var2pos_stack[var_elem][-1] if len(self._var2pos_stack[var_elem]) > 0 else None

    def var_must_be_moved(self, var_elem: var_id_T, cstate: SymbolicState) -> Tuple[bool, int]:
        """
        By construction, a var element must be moved if there is an available position in which it
        appears in the final stack (and it is not yet in its position). Return whether it is possible to
        perform the movement and the position the var element must be placed
        """
        topmost_idx_fstack = idx_wrt_fstack(0, cstate.stack, self._final_stack)
        # Condition: the topmost element is not placed in its corresponding position yet
        if topmost_idx_fstack < 0 or self._final_stack[topmost_idx_fstack] != var_elem:
            # Find the first position to which it can be moved
            next_available_pos = next(self._available_positions(var_elem, cstate), None)
            return next_available_pos is not None, next_available_pos
        return False, -1

    def choose_next_computation(self, cstate: SymbolicState) -> instr_id_T:
        """
        Returns an element from mops, sops or lops and where it came from (mops, sops or lops)
        TODO: Here we should try to devise a good heuristics to select the terms
        """

        candidates = self._compute_candidates(cstate)
        candidate = self._score_candidate(candidates, cstate)
        return candidate

    def _compute_candidates(self, dependency_graph: networkx.DiGraph) -> List[instr_id_T]:
        """
        Retrieves all the candidates consider for choosing the next computation. This includes the list of instructions
        with no other dependency and the stack variables that must be duplicated
        """
        return [id_ for id_ in dependency_graph.nodes if dependency_graph.out_degree(id_) == 0]

    def _score_candidate(self, candidates: List[instr_id_T], cstate: SymbolicState) -> instr_id_T:
        current_top = cstate.top_stack()
        best_candidate_info = False, dict()
        candidate = None

        for id_ in candidates:
            top_instr = self._id2instr[id_]
            deepest_pos = dict()

            # Function invocations might generate multiple values that we should take into account
            for out_var in top_instr['outpt_sk']:
                # We detect which is the deepest position in which the element can be placed
                deepest_occurrence = self._deepest_position(out_var)
                if deepest_occurrence is not None:
                    deepest_pos[out_var] = deepest_occurrence

            # We can reuse the topmost element
            uses_top = current_top is not None and current_top in self._top_can_be_used[id_]
            current_candidate_info = uses_top, deepest_pos

            # To decide whether the current candidate is the best so far, we use the information from deepest_pos
            # and reuses_pos
            better_candidate = self._le_ranked_options(best_candidate_info, current_candidate_info)
            if better_candidate:
                candidate = id_
                best_candidate_info = current_candidate_info

            self.debug_logger.debug_rank_candidates(id_, current_candidate_info, better_candidate)

        assert candidate is not None, "Loop of _score_candidate must assign one candidate"
        return candidate

    def _le_ranked_options(self, option1: Tuple[bool, Dict[var_id_T, int]],
                           option2: Tuple[bool, Dict[var_id_T, int]]) -> bool:
        # First we prioritize whether it can reuse the topmost element
        if option1[0] != option2[0]:
            return option2[0]
        opt1_deepest = max(option1[1].values(), default=-1)
        opt2_deepest = max(option2[1].values(), default=-1)
        return opt1_deepest <= opt2_deepest

    def compute_instr(self, instr: instr_JSON_T, cstate: SymbolicState, terms_to_dup: List[var_id_T]) -> List[
        instr_id_T]:
        """
        Given an instr, the current state and the terms that need to be duplicated, computes the corresponding term.
        This function is separated from compute_op because there
        are terms, such as var accesses or memory accesses that produce no var element as a result.
        """
        self.debug_logger.debug_compute_instr(instr, cstate)

        seq = []

        # First, we compute the subterms to dup
        for term in terms_to_dup:
            # TODO: decide order in terms to dup
            seq.extend(self.compute_var(term, cstate))

        # Decide in which order computations must be done (after computing the subterms)
        input_vars = self._computation_order(instr, cstate)
        first_element = True

        for stack_var in input_vars:
            top_elem = cstate.top_stack()
            # If we can reuse the first element and this element must be not consumed elsewhere
            if first_element and top_elem is not None and top_elem == stack_var and \
                    cstate.var_uses[top_elem] == self._var_total_uses[top_elem]:
                self.fixed_elements += 1
            else:
                # Otherwise, we must return generate it with a recursive call
                seq.extend(self.compute_var(stack_var, cstate))

            first_element = False

        # Finally, we compute the element
        seq.extend(cstate.uf(instr))

        # Update the number of fixed elements afterwards
        self.fixed_elements -= len(instr['inpt_sk'])
        self.fixed_elements += len(instr['outpt_sk'])
        return seq

    def _computation_order(self, instr: instr_JSON_T, cstate: SymbolicState) -> List[var_id_T]:
        """
        Decides in which order the arguments of the instruction must be computed
        """
        if instr['commutative']:
            # If it's commutative, study its dependencies.
            if self.debug_mode:
                assert len(instr['inpt_sk']) == 2, \
                    f'Commutative instruction {instr["id"]} has arity != 2'

            # Condition: the top of the stack can be reused
            topmost_element = cstate.top_stack()
            first_arg_instr = self._var2instr.get(instr['inpt_sk'][0], None)

            # Condition: the topmost element can be reused by the first argument instruction or is the first argument
            if (topmost_element is not None and topmost_element in self._top_can_be_used[instr["id"]] and
                    first_arg_instr is not None and
                    (first_arg_instr["outpt_sk"][0] == topmost_element or
                     topmost_element in self._top_can_be_used[first_arg_instr["id"]])):
                input_vars = instr['inpt_sk']
            else:
                input_vars = list(reversed(instr['inpt_sk']))
        else:
            input_vars = list(reversed(instr['inpt_sk']))
        return input_vars

    def _identify_subterms_to_dup(self, instr: instr_JSON_T, cstate: SymbolicState) -> List[var_id_T]:
        """
        First we identify which subterms must be duplicated in order to compute them first
        """
        # We return the variables that are not needed twice
        return [stack_var for stack_var in self._values_used[instr["id"]]
                if cstate.var_uses[stack_var] < self._var_total_uses[stack_var] - 1 and
                (((associated_instr := self._var2instr.get(stack_var, None)) is None) or not cheap(associated_instr))]

    def compute_var(self, var_elem: var_id_T, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Given a stack_var and current state, computes the element and updates cstate accordingly. Returns the sequence of ids.
        Compute var considers it the var elem is already stored in the stack
        """
        self.debug_logger.debug_compute_var(var_elem, cstate)
        # First case: the element has not been computed previously. We have to compute it, as it
        # corresponds to a stack variable
        if cstate.var_uses[var_elem] == 0:
            instr = self._var2instr[var_elem]
            seq = self.compute_instr(instr, cstate, [])

        # Second case: the variable has already been computed (i.e. var_uses > 0).
        # In this case, we duplicate it or retrieve it from memory
        else:

            # If the instruction is cheap, we compute it again
            instr = self._var2instr.get(var_elem, None)
            if instr is not None and cheap(instr):
                seq = self.compute_instr(instr, cstate, [])
            else:
                assert var_elem in cstate.stack, f"Variable {var_elem} must appear in the stack, " \
                                                 f"as it was previously computed and it is not a cheap computation"
                # TODO: case for recomputing the element?
                # Case I: We swap the element the number of copies required is met, the position is accessible
                # and there is no fixed stack elements
                if cstate.is_accessible_swap(var_elem) and cstate.var_uses[var_elem] == self._var_total_uses[var_elem] \
                        and self.fixed_elements == 0:
                    # We swap to the deepest accesible copy
                    idx = cstate.last_accessible_occurrence(var_elem)
                    seq = cstate.swap(idx)
                    self.debug_logger.debug_message(f"SWAP{idx} {cstate.stack}")

                # Case II: we duplicate the element that is within reach
                elif cstate.is_accessible_dup(var_elem):
                    idx = cstate.first_occurrence(var_elem) + 1
                    seq = cstate.dup(idx)
                    self.debug_logger.debug_message(f"DUP{idx} {cstate.stack}")

                # Case III: we retrieve the element from memory
                else:
                    seq = cstate.from_memory(var_elem)

                # We have computed the corresponding element
                self.fixed_elements += 1
        return seq

    def solve_permutation(self, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Places all the elements in their corresponding positions
        """
        # TODO: complete code
        return []


class DebugLogger:
    """
    Class that contains the multiple debugging messages for the greedy algorithm
    """

    def __init__(self):
        self._logger = logging.getLogger("greedy")

    def debug_initial(self, ops: List[instr_id_T]):
        self._logger.debug("---- Initial Ops ----")
        self._logger.debug(f'Ops:{ops}')
        self._logger.debug("")

    def debug_loop(self, dep_graph, optg: List[instr_id_T],
                   cstate: SymbolicState):
        self._logger.debug("---- While loop ----")
        self._logger.debug(f"Ops not computed {list(dep_graph.nodes)}")
        self._logger.debug(f"Ops computed: {optg}")
        self._logger.debug(cstate)
        self._logger.debug("")

    def debug_pop(self, var_top: var_id_T, cstate: SymbolicState):
        self._logger.debug("---- Drop term ----")
        self._logger.debug(f"Var Term: {var_top}")
        self._logger.debug(f'State {cstate}')
        self._logger.debug("")

    def debug_move_var(self, var_top: var_id_T, position: int, cstate: SymbolicState):
        self._logger.debug("---- Move var to position ----")
        self._logger.debug(f"Var Term: {var_top}")
        self._logger.debug(f"Position: {position}")
        self._logger.debug(f'State {cstate}')
        self._logger.debug("")

    def debug_rank_candidates(self, candidate: instr_id_T, candidate_score: Tuple[bool, Dict[var_id_T, int]],
                              chosen: bool):
        self._logger.debug("---- Score candidate ----")
        self._logger.debug(f"Candidate {candidate}")
        self._logger.debug(f'Candidate score {candidate_score}')
        self._logger.debug("Candidate has been chosen" if chosen else "Candidate does not improve")
        self._logger.debug("")

    def debug_choose_computation(self, next_id: instr_id_T, cstate: SymbolicState):
        self._logger.debug("---- Computation chosen ----")
        self._logger.debug(next_id)
        self._logger.debug(cstate)
        self._logger.debug("")

    def debug_terms_to_dup(self, terms_to_dup: List[var_id_T]):
        self._logger.debug("---- Terms to duplicate before computation ----")
        self._logger.debug(terms_to_dup)
        self._logger.debug("")

    def debug_compute_instr(self, instr: instr_JSON_T, cstate: SymbolicState):
        self._logger.debug("---- Computing instr ----")
        self._logger.debug(instr)
        self._logger.debug(f"Stack: {cstate.stack}")
        self._logger.debug("")

    def debug_compute_var(self, var: var_id_T, cstate: SymbolicState):
        self._logger.debug("---- Computing variable ----")
        self._logger.debug(var)
        self._logger.debug(f"Stack: {cstate.stack}")
        self._logger.debug("")

    def debug_after_permutation(self, cstate: SymbolicState, optg: List[instr_id_T]):
        self._logger.debug("---- State after solving permutation ----")
        self._logger.debug(cstate)
        self._logger.debug(optg)
        self._logger.debug("")

    def debug_message(self, message: str):
        self._logger.debug(message)


def greedy_standalone(sms: Dict) -> Tuple[str, float, List[str]]:
    """
    Executes the greedy algorithm as a standalone configuration. Returns whether the execution has been
    sucessful or not ("non_optimal" or "error"), the total time and the sequence of ids returned.
    """
    error = 0
    usage_start = resource.getrusage(resource.RUSAGE_SELF)
    try:
        seq_ids = SMSgreedy(sms).greedy()
        usage_stop = resource.getrusage(resource.RUSAGE_SELF)
    except Exception as e:
        usage_stop = resource.getrusage(resource.RUSAGE_SELF)
        _, _, tb = sys.exc_info()
        traceback.print_tb(tb)
        print(e, file=sys.stderr)
        error = 1
        seq_ids = []
    optimization_outcome = "error" if error == 1 else "non_optimal"
    return optimization_outcome, usage_stop.ru_utime + usage_stop.ru_stime - usage_start.ru_utime - usage_start.ru_stime, seq_ids


def greedy_from_file(filename: str) -> Tuple[SMS_T, List[instr_id_T]]:
    logging.basicConfig(level=logging.DEBUG)
    with open(filename, "r") as f:
        sfs = json.load(f)
    outcome, time, ids = greedy_standalone(sfs)
    return sfs, ids


if __name__ == "__main__":
    greedy_from_file(sys.argv[1])
