#!/usr/bin/env python3
import itertools
import json
import logging
import resource
import sys
import os
from typing import List, Dict, Tuple, Any, Set, Optional, Generator
from collections import defaultdict, Counter
import traceback
from enum import Enum, unique

import networkx
import networkx as nx
# from analysis.greedy_validation import check_execution_from_ids
from global_params.types import var_id_T, instr_id_T, instr_JSON_T, SMS_T

# Specific type to identify which positions corresponds to the ones
# in the current and final stacks
cstack_pos_T = int
fstack_pos_T = int

# Annotation for the maximum stack depth that can be managed through operations
STACK_DEPTH = 16


def _simplify_graph_to_selected_nodes(graph: nx.DiGraph, selected_nodes: List) -> nx.DiGraph:
    """
    Auxiliary method that returns the transitive reduction of the graph that is generated by
    preserving the initial paths in the original path when restricted to the selected nodes
    """
    subgraph = nx.DiGraph()
    subgraph.add_nodes_from(selected_nodes)

    # Add edges based on reachability using BFS/DFS
    for u in selected_nodes:
        for v in selected_nodes:
            # Avoid self-loops and skips relations that have already been considered
            if u != v and not subgraph.has_edge(v, u):

                # Check if v is reachable from u in G using DFS
                reachable = nx.algorithms.dfs_predecessors(graph, source=u)
                if v in reachable:
                    subgraph.add_edge(u, v)

    # Step 4: Apply transitive reduction on the dynamically created subgraph
    subgraph_reduced = nx.transitive_reduction(subgraph)
    return subgraph_reduced


def idx_wrt_cstack(idx: fstack_pos_T, cstack: List, fstack: List) -> cstack_pos_T:
    """
    Given a position w.r.t fstack, returns the corresponding position w.r.t cstack
    """
    return idx - len(fstack) + len(cstack)


def idx_wrt_fstack(idx: cstack_pos_T, cstack: List, fstack: List) -> fstack_pos_T:
    """
    Given a position w.r.t cstack, returns the corresponding position w.r.t fstack
    """
    return idx - len(cstack) + len(fstack)


def top_relative_position_to_fstack(cstack: List[var_id_T], fstack: List[var_id_T]) -> int:
    return idx_wrt_fstack(0, cstack, fstack)


def extract_idx_from_id(instr_id: str) -> int:
    return int(instr_id.split('_')[-1])


def cheap(instr: instr_JSON_T) -> bool:
    """
    Cheap computations are those who take one instruction (i.e. inpt_sk is empty)
    """
    return len(instr['inpt_sk']) == 0 and instr["size"] <= 2


class SymbolicState:
    """
    A symbolic state includes a stack, and a dict indicating the number of total uses of each
    instruction
    """

    def __init__(self, stack: List[var_id_T]) -> None:
        self.stack: List[var_id_T] = stack

        # Var uses counts how many times the corresponding variables appears in the current stack
        self.var_uses: Dict[var_id_T, int] = self._computer_var_uses()

        self.debug_mode = True

    def _computer_var_uses(self):
        var_uses = defaultdict(lambda: 0)

        # Count vars in the initial stack
        for var_stack in self.stack:
            var_uses[var_stack] += 1

        return var_uses

    def swap(self, x: int) -> List[instr_id_T]:
        """
        Stores the top of the stack in the local with index x. in_position marks whether the element is
        solved in flocals
        """
        assert 0 <= x < len(self.stack), f"Swapping with index {x} a stack of {len(self.stack)} elements: {self.stack}"
        self.stack[0], self.stack[x] = self.stack[x], self.stack[0]

        # Var uses: no modification, as we are just moving two elements
        return [f"SWAP{x}"]

    def dup(self, x: int) -> List[instr_id_T]:
        """
        Tee instruction in local with index x. in_position marks whether the element is solved in flocals
        """
        idx = x - 1
        assert 0 <= idx < len(self.stack), \
            f"Duplicating index {x} in a stack in {len(self.stack)} elements: {self.stack}"
        self.stack.insert(0, self.stack[idx])

        # Var uses: we increment the element that we have in its corresponding position
        self.var_uses[self.stack[0]] += 1
        return [f"DUP{x}"]

    def pop(self) -> List[instr_id_T]:
        """
        Drops the last element
        """
        stack_var = self.stack.pop(0)

        # Var uses: we subtract one because the stack var is totally removed from the encoding
        self.var_uses[stack_var] -= 1
        return ["POP"]

    def uf(self, instr: instr_JSON_T) -> List[instr_id_T]:
        """
        Symbolic execution of instruction instr. Additionally, checks the arguments match if debug mode flag is enabled
        """
        consumed_elements = [self.stack.pop(0) for _ in range(len(instr['inpt_sk']))]

        # Neither liveness nor var uses are affected by consuming elements, as these elements are just being embedded
        # into a new term
        # Debug mode to check the pop args from the stack match
        if self.debug_mode:
            if instr['commutative']:
                # Compare them as multisets
                assert Counter(consumed_elements) == Counter(instr['inpt_sk']), \
                    f"{instr['id']} is not consuming the correct elements from the stack"
            else:
                # Compare them as lists
                assert consumed_elements == instr['inpt_sk'], \
                    f"{instr['id']} is not consuming the correct elements from the stack"

        # We introduce the new elements
        for output_var in instr['outpt_sk']:
            self.stack.insert(0, output_var)
            # Var uses: increase one for each generated stack var
            self.var_uses[output_var] += 1

        return [instr["id"]]

    def from_memory(self, var_elem: var_id_T) -> List[instr_id_T]:
        """
        Assumes the value is retrieved from memory
        """
        self.stack.insert(0, var_elem)

        # Var uses: increase one for the variable
        self.var_uses[var_elem] += 1

        return [f"MEM({var_elem})"]

    def top_stack(self) -> Optional[var_id_T]:
        return None if len(self.stack) == 0 else self.stack[0]

    def is_accessible_swap(self, var_elem: var_id_T) -> bool:
        """
        Checks whether the variable element can be accessed for a swap instruction
        """
        return self.stack.index(var_elem) <= STACK_DEPTH

    def is_accessible_dup(self, var_elem: var_id_T) -> bool:
        """
        Checks whether the variable element can be accessed for a dup instruction
        """
        return self.stack.index(var_elem) < STACK_DEPTH

    def first_occurrence(self, var_elem: var_id_T) -> int:
        """
        Returns the first position in which the element appears
        """
        try:
            return self.stack.index(var_elem)
        except:
            return -1

    def last_accessible_occurrence(self, var_elem: var_id_T) -> int:
        """
        Returns the first position in which the element appears
        """
        try:
            return self.stack.index(var_elem)
        except:
            return -1

    def __repr__(self):
        return str(self.stack)


class SMSgreedy:

    def __init__(self, json_format: SMS_T):
        self.debug_mode: bool = True
        # How many elements are placed in the correct position and cannot be moved further in a computation
        self.fixed_elements: int = 0
        self._user_instr: List[instr_JSON_T] = json_format['user_instrs']
        self._initial_stack: List[var_id_T] = json_format['src_ws']
        self._final_stack: List[var_id_T] = json_format['tgt_ws']
        self._deps: List[Tuple[var_id_T, var_id_T]] = json_format['dependencies']
        self.debug_logger = DebugLogger()

        # Note: we assume function invocations might have several variables in 'outpt_sk'
        self._var2instr = {var: ins for ins in self._user_instr for var in ins['outpt_sk']}
        self._id2instr = {ins['id']: ins for ins in self._user_instr}
        self._var2id = {var: ins['id'] for ins in self._user_instr for var in ins['outpt_sk']}
        self._var2pos_stack = self._compute_var2pos(self._final_stack)

        self._var_total_uses = self._compute_var_total_uses()
        direct_g, indirect_g = self._compute_dependency_graph()

        self._relevant_ops = self.select_ops(direct_g)
        self._indirect_g = _simplify_graph_to_selected_nodes(indirect_g, self._relevant_ops)
        self._direct_g = _simplify_graph_to_selected_nodes(direct_g, self._relevant_ops)

        # We determine which elements must be computed in order to compute certain instruction
        self._values_used = {}
        for instr_id in self._relevant_ops:
            self._compute_values_used(self._id2instr[instr_id], self._relevant_ops, self._values_used)

        # Determine which topmost elements can be reused in the graph
        self._top_can_be_used = {}
        for instr in self._user_instr:
            self._compute_top_can_used(instr, self._top_can_be_used)

        # We need to compute the sub graph over the full dependency graph, as edges could be lost if we use the
        # transitive reduction instead. Hence, we need to compute the transitive_closure of the graph
        self._trans_sub_graph = nx.transitive_reduction(nx.DiGraph([*self._direct_g.edges, *self._indirect_g.edges]))
        for node in self._relevant_ops:
            self._trans_sub_graph.add_node(node)

    def _compute_var_total_uses(self) -> Dict[var_id_T, int]:
        """
        Computes how many times each var appears either in the final stack or as a subterm
        for other terms.
        """
        var_uses = defaultdict(lambda: 0)

        # Count vars in the final stack
        for var_stack in self._final_stack:
            var_uses[var_stack] += 1

        # Count vars as input of other instrs
        for instr_id, instr in self._id2instr.items():
            for subterm_var in instr['inpt_sk']:
                var_uses[subterm_var] += 1

        return var_uses

    def _compute_var2pos(self, var_list: List[var_id_T]) -> Dict[var_id_T, List[int]]:
        """
        Dict that links each stack variable that appears in a var list to the
        list of positions it occupies
        """
        var2pos = defaultdict(lambda: [])

        for i, stack_var in enumerate(var_list):
            var2pos[stack_var].append(i)

        return var2pos

    def _compute_dependency_graph(self) -> Tuple[nx.DiGraph, nx.DiGraph]:
        """
        We generate two dependency graphs: one for direct relations (i.e. one term embedded into another)
        and other with the dependencies due to memory/storage accesses
        """
        direct_graph = nx.DiGraph()
        indirect_graph = nx.DiGraph()

        for instr in self._user_instr:
            instr_id = instr['id']
            direct_graph.add_node(instr_id)
            indirect_graph.add_node(instr_id)

            for stack_elem in instr['inpt_sk']:
                # This means the stack element corresponds to another uninterpreted instruction
                if stack_elem in self._var2instr:
                    direct_graph.add_edge(self._var2id[stack_elem], instr_id)

        # We need to consider also the order given by the tuples
        for id1, id2 in self._deps:
            indirect_graph.add_edge(id1, id2)

        return direct_graph, indirect_graph

    def select_ops(self, direct_g: nx.DiGraph):
        """
        Selects which operations are considered in the algorithm. We consider mem operations (excluding loads with no
        dependencies) and computations that are not subterms
        """
        dep_ids = set(elem for dep in self._deps for elem in dep)

        # Relevant operations corresponds to memory operations (STORE in all cases, LOADs an KECCAKs if they have some
        # some kind of dependency) and operations that are not used elsewhere. The idea here is that we want
        # to consider the maximal elements to compute, as reusing computations is easier this way
        relevant_operations = [instr["id"] for instr in self._user_instr if
                               any(instr_name in instr["disasm"] for instr_name in ["STORE"])
                               or (any(load_instr in instr["disasm"] for load_instr in ["LOAD", "KECCAK"])
                                   and instr["id"] in dep_ids)
                               or direct_g.out_degree(instr["id"]) == 0]
        return relevant_operations

    def _compute_top_can_used(self, instr: instr_JSON_T, top_can_be_used: Dict[var_id_T, Set[var_id_T]]) -> Set[var_id_T]:
        """
        Computes for each instruction if the topmost element of the stack can be reused directly
        at some point. It considers commutative operations
        """
        reused_elements = top_can_be_used.get(instr["id"], None)
        if reused_elements is not None:
            return reused_elements

        current_uses = set()
        comm = instr["commutative"]
        first_element = True
        for stack_var in reversed(instr["inpt_sk"]):
            # We only consider the first element if the operation is not commutative, or both elements otherwise
            if comm or first_element:
                instr_bef = self._var2instr.get(stack_var, None)
                if instr_bef is not None:
                    instr_bef_id = instr_bef["id"]
                    if instr_bef_id not in top_can_be_used:
                        current_uses.update(self._compute_top_can_used(instr_bef, top_can_be_used))
                    else:
                        current_uses.update(top_can_be_used[instr_bef_id])
                    # Add only instructions that are relevant to our context
                    current_uses.add(stack_var)
            else:
                break
            first_element = False

        top_can_be_used[instr["id"]] = current_uses
        return current_uses

    def _compute_values_used(self, instr: instr_JSON_T, relevant_ops: List[instr_id_T],
                             value_uses: Dict[var_id_T, Set[var_id_T]]) -> Set[var_id_T]:
        """
        For a given instruction, determines which stack elements must be computed
        """
        values_used = value_uses.get(instr["id"], None)
        if values_used is not None:
            return values_used

        current_uses = set()
        for stack_var in instr["inpt_sk"]:
            instr_bef = self._var2instr.get(stack_var, None)
            if instr_bef is not None:
                instr_bef_id = instr_bef["id"]
                if instr_bef_id not in value_uses:
                    current_uses.update(self._compute_values_used(instr_bef, relevant_ops, value_uses))
                else:
                    current_uses.update(value_uses[instr_bef_id])
                # Add only instructions that are relevant to our context
                if instr_bef_id in relevant_ops:
                    current_uses.add(stack_var)
            else:
                current_uses.add(stack_var)
        value_uses[instr["id"]] = current_uses
        return current_uses

    def greedy(self) -> List[instr_id_T]:
        """
        Main implementation of the greedy algorithm (i.e. the instruction scheduling algorithm)
        """
        cstate: SymbolicState = SymbolicState(self._initial_stack)

        dep_graph = self._trans_sub_graph.copy()
        optg = []

        self.debug_logger.debug_initial(dep_graph.nodes)

        # For easier code, we end the while when we need to choose an
        # operation and there are no operations left
        while True:
            var_top = cstate.top_stack()
            self.fixed_elements = 0

            self.debug_logger.debug_loop(dep_graph, optg, cstate)

            # Case 1: Top of the stack must be removed, as it appears more time it is being used
            if var_top is not None and cstate.var_uses[var_top] > self._var_total_uses[var_top]:
                self.debug_logger.debug_pop(var_top, cstate)
                optg.extend(cstate.pop())

            # Case 2: Top of the stack must be placed in some other position
            elif var_top is not None and self.var_must_be_moved(var_top, cstate):
                optg.extend(self.move_top_to_position(var_top, cstate))

            # Case 3: Top of the stack cannot be moved to the corresponding position.
            # Hence, we just generate the following computation
            else:
                # There are no operations left to choose, so we stop the search
                if len(dep_graph.nodes) == 0:
                    break

                next_id = self.choose_next_computation(cstate, dep_graph)
                next_instr = self._id2instr[next_id]
                self.debug_logger.debug_choose_computation(next_id, cstate)

                terms_to_dup = self._identify_subterms_to_dup(next_instr, cstate)
                ops = self.compute_instr(next_instr, cstate, terms_to_dup)

                # Cheap instructions are just computed, there is no need to erase elements from the lists
                dep_graph.remove_node(next_id)
                nx.nx_agraph.write_dot(dep_graph, "dep_graph.dot")

                optg.extend(ops)

        optg.extend(self.solve_permutation(cstate))
        self.debug_logger.debug_after_permutation(cstate, optg)

        return optg

    def _available_positions(self, var_elem: var_id_T, cstate: SymbolicState) -> Generator[cstack_pos_T, None, None]:
        """
        Generator for the set of available positions in cstack where the var element can be placed
        """
        # We just need to check that the positions in which the element appears in the
        # final stack are in range and not contain the element
        for position in reversed(self._var2pos_stack[var_elem]):
            fidx = idx_wrt_cstack(position, cstate.stack, self._final_stack)

            # When the index is negative, it means there are not enough elements in cstack
            # to place the corresponding element
            if fidx < 0:
                break

            # A variable must be moved when a positive index is found (less than STACK_DEPTH)
            # which does not contain yet the corresponding element
            elif STACK_DEPTH >= fidx >= 0 and cstate.stack[fidx] != var_elem:
                yield position

    def var_must_be_moved(self, var_elem: var_id_T, cstate: SymbolicState) -> bool:
        """
        By construction, a var element must be moved if there is an available position in which it
        appears in the final stack (and it is not yet in its position)
        """
        topmost_idx_fstack = idx_wrt_fstack(0, cstate.stack, self._final_stack)
        return (topmost_idx_fstack > 0 and self._final_stack[topmost_idx_fstack] != var_elem) and \
            next(self._available_positions(var_elem, cstate), None) is not None

    def move_top_to_position(self, var_elem: var_id_T, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Stores the current element in all the deepest available position.
        """
        # TODO: decide if we just want to move one element or duplicate it as many
        #  times as it is possible
        # We just need to retrieve the deepest element
        deepest_position_available = next(self._available_positions(var_elem, cstate), None)

        assert deepest_position_available is not None, f"There is no available position to move {var_elem}"

        # There is no need to move the element to other position
        if deepest_position_available == 0:
            return []

        return cstate.swap(deepest_position_available)

    def choose_next_computation(self, cstate: SymbolicState, dep_graph: networkx.DiGraph) -> instr_id_T:
        """
        Returns an element from mops, sops or lops and where it came from (mops, sops or lops)
        TODO: Here we should try to devise a good heuristics to select the terms
        """

        candidates = self._compute_candidates(dep_graph)
        candidate = self._score_candidate(candidates, cstate)
        return candidate

    def _compute_candidates(self, dependency_graph: networkx.DiGraph) -> List[instr_id_T]:
        """
        Retrieves all the candidates consider for choosing the next computation.
        """
        return [id_ for id_ in dependency_graph.nodes if dependency_graph.in_degree(id_) == 0]

    def _score_candidate(self, candidates: List[instr_id_T], cstate: SymbolicState) -> instr_id_T:
        current_top = cstate.top_stack()
        best_candidate_info = False, dict()
        candidate = None

        for id_ in candidates:
            top_instr = self._id2instr[id_]
            deepest_pos = dict()

            # Function invocations might generate multiple values that we should take into account
            for out_var in top_instr['outpt_sk']:
                # We detect which is the deepest position in which the element can be placed
                deepest_occurrence = next(self._available_positions(out_var, cstate), None)
                if deepest_occurrence is not None:
                    deepest_pos[out_var] = deepest_occurrence

            # We can reuse the topmost element
            uses_top = current_top is not None and current_top in self._top_can_be_used[id_]
            current_candidate_info = uses_top, deepest_pos

            # To decide whether the current candidate is the best so far, we use the information from deepest_pos
            # and reuses_pos
            better_candidate = self._le_ranked_options(best_candidate_info, current_candidate_info)
            if better_candidate:
                candidate = id_
                best_candidate_info = current_candidate_info

            self.debug_logger.debug_rank_candidates(id_, current_candidate_info, better_candidate)

        assert candidate is not None, "Loop of _score_candidate must assign one candidate"
        return candidate

    def _le_ranked_options(self, option1: Tuple[bool, Dict[var_id_T, int]], option2: Tuple[bool, Dict[var_id_T, int]]) -> bool:
        # First we prioritize whether it can reuse the topmost element
        if option1[0] != option2[0]:
            return option2[0]
        opt1_deepest = max(option1[1].values(), default=-1)
        opt2_deepest = max(option2[1].values(), default=-1)
        return opt1_deepest <= opt2_deepest

    def compute_instr(self, instr: instr_JSON_T, cstate: SymbolicState, terms_to_dup: List[var_id_T]) -> List[instr_id_T]:
        """
        Given an instr, the current state and the terms that need to be duplicated, computes the corresponding term.
        This function is separated from compute_op because there
        are terms, such as var accesses or memory accesses that produce no var element as a result.
        """
        seq = []

        # First, we compute the subterms to dup
        for term in terms_to_dup:
            # TODO: decide order in terms to dup
            seq.extend(self.compute_var(term, cstate))

        # Decide in which order computations must be done (after computing the subterms)
        input_vars = self._computation_order(instr, cstate)
        first_element = True

        for stack_var in input_vars:
            top_elem = cstate.top_stack()
            if first_element and top_elem is not None and top_elem == stack_var:
                if cstate.var_uses[top_elem] < self._var_total_uses[top_elem]:
                    top_instr = self._var2instr.get(top_elem, None)

                    # Only storee it in a local if needed
                    if not cheap(top_instr):
                        seq.extend(self.move_top_to_position(top_elem, cstate))
                    else:
                        seq.extend(self.compute_var(top_elem, cstate))

            else:
                # Otherwise, we must return generate it with a recursive call
                seq.extend(self.compute_var(stack_var, cstate))

            first_element = False

        # Finally, we compute the element
        seq.extend(cstate.uf(instr))

        # Update the number of fixed elements afterwards
        self.fixed_elements -= len(instr['inpt_sk'])
        self.fixed_elements += len(instr['outpt_sk'])
        return seq

    def _computation_order(self, instr: instr_JSON_T, cstate: SymbolicState) -> List[var_id_T]:
        """
        Decides in which order the arguments of the instruction must be computed
        """
        if instr['commutative']:
            # If it's commutative, study its dependencies.
            if self.debug_mode:
                assert len(instr['inpt_sk']) == 2, \
                    f'Commutative instruction {instr["id"]} has arity != 2'

            # Condition: the top of the stack can be reused
            topmost_element = cstate.top_stack()
            first_arg_instr = self._var2instr.get(instr['inpt_sk'][0], None)

            # Condition: the topmost element can be reused by the first argument instruction or is the first argument
            if (topmost_element is not None and topmost_element in self._top_can_be_used[instr["id"]] and
                    first_arg_instr is not None and
                    (first_arg_instr["outpt_sk"][0] == topmost_element or
                     topmost_element in self._top_can_be_used[first_arg_instr["id"]])):
                input_vars = instr['inpt_sk']
            else:
                input_vars = list(reversed(instr['inpt_sk']))
        else:
            input_vars = list(reversed(instr['inpt_sk']))
        return input_vars

    def _identify_subterms_to_dup(self, instr: instr_JSON_T, cstate: SymbolicState) -> List[var_id_T]:
        """
        First we identify which subterms must be duplicated in order to compute them first
        """
        # We return the variables that are not needed twice
        return [stack_var for stack_var in self._values_used[instr["id"]]
                if cstate.var_uses[stack_var] < self._var_total_uses[stack_var] - 1 and
                (((associated_instr := self._var2instr.get(stack_var, None)) is None) or not cheap(associated_instr))]

    def compute_var(self, var_elem: var_id_T, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Given a stack_var and current state, computes the element and updates cstate accordingly. Returns the sequence of ids.
        Compute var considers it the var elem is already stored in the stack
        """
        # First case: the element has not been computed previously. We have to compute it, as it
        # corresponds to a stack variable
        if cstate.var_uses[var_elem] == 0:
            instr = self._var2instr[var_elem]
            seq = self.compute_instr(instr, cstate, [])

        # Second case: the variable has already been computed (i.e. var_uses > 0).
        # In this case, we duplicate it or retrieve it from memory
        else:

            # If the instruction is cheap, we compute it again
            instr = self._var2instr.get(var_elem, None)
            if instr is not None and cheap(instr):
                seq = self.compute_instr(instr, cstate, [])
            else:
                assert var_elem in cstate.stack, f"Variable {var_elem} must appear in the stack, " \
                                                 f"as it was previously computed and it is not a cheap computation"
                # TODO: case for recomputing the element?
                # Case I: We swap the element the number of copies required is met, the position is accessible
                # and there is no fixed stack elements
                if cstate.is_accessible_swap(var_elem) and cstate.var_uses[var_elem] == self._var_total_uses[var_elem] \
                        and self.fixed_elements == 0:
                    # We swap to the deepest accesible copy
                    idx = cstate.last_accessible_occurrence(var_elem) + 1
                    seq = cstate.swap(idx)

                # Case II: we duplicate the element that is within reach
                elif cstate.is_accessible_dup(var_elem):
                    idx = cstate.first_occurrence(var_elem) + 1
                    seq = cstate.dup(idx)

                # Case III: we retrieve the element from memory
                else:
                    seq = cstate.from_memory(var_elem)

        return seq

    def solve_permutation(self, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Places all the elements in their corresponding positions
        """
        # TODO: complete code
        return []


class DebugLogger:

    """
    Class that contains the multiple debugging messages for the greedy algorithm
    """
    
    def __init__(self):
        self._logger = logging.getLogger("greedy")

    def debug_initial(self, ops: List[instr_id_T]):
        self._logger.debug("---- Initial Ops ----")
        self._logger.debug(f'Ops:{ops}')
        self._logger.debug("")

    def debug_loop(self, dep_graph, optg: List[instr_id_T],
                    cstate: SymbolicState):
        self._logger.debug("---- While loop ----")
        self._logger.debug(f"Ops not computed {list(dep_graph.nodes)}")
        self._logger.debug(f"Ops computed: {optg}")
        self._logger.debug(cstate)
        self._logger.debug("")

    def debug_pop(self, var_top: var_id_T, cstate: SymbolicState):
        self._logger.debug("---- Drop term ----")
        self._logger.debug(f"Var Term: {var_top}")
        self._logger.debug(f'State {cstate}')
        self._logger.debug("")

    def debug_rank_candidates(self, candidate: instr_id_T, candidate_score: Tuple[bool, Dict[var_id_T, int]], chosen: bool):
        self._logger.debug("---- Score candidate ----")
        self._logger.debug(f"Candidate {candidate}")
        self._logger.debug(f'Candidate score {candidate_score}')
        self._logger.debug("Candidate has been chosen" if chosen else "Candidate does not improve")
        self._logger.debug("")

    def debug_choose_computation(self, next_id: instr_id_T, cstate: SymbolicState):
        self._logger.debug("---- Computation chosen ----")
        self._logger.debug(next_id)
        self._logger.debug(cstate)
        self._logger.debug("")

    def debug_after_permutation(self, cstate: SymbolicState, optg: List[instr_id_T]):
        self._logger.debug("---- State after solving permutation ----")
        self._logger.debug(cstate)
        self._logger.debug(optg)
        self._logger.debug("")


def greedy_standalone(sms: Dict) -> Tuple[str, float, List[str]]:
    """
    Executes the greedy algorithm as a standalone configuration. Returns whether the execution has been
    sucessful or not ("non_optimal" or "error"), the total time and the sequence of ids returned.
    """
    error = 0
    usage_start = resource.getrusage(resource.RUSAGE_SELF)
    try:
        seq_ids = SMSgreedy(sms).greedy()
        usage_stop = resource.getrusage(resource.RUSAGE_SELF)
    except Exception as e:
        usage_stop = resource.getrusage(resource.RUSAGE_SELF)
        _, _, tb = sys.exc_info()
        traceback.print_tb(tb)
        error = 1
        seq_ids = []
    optimization_outcome = "error" if error == 1 else "non_optimal"
    return optimization_outcome, usage_stop.ru_utime + usage_stop.ru_stime - usage_start.ru_utime - usage_start.ru_stime, seq_ids


if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    with open(sys.argv[1], "r") as f:
        sfs = json.load(f)
    outcome, time, ids = greedy_standalone(sfs)
