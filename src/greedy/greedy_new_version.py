#!/usr/bin/env python3
import itertools
import json
import logging
import sys
import os
from typing import List, Dict, Tuple, Any, Set, Optional, Generator
from collections import defaultdict, Counter
import traceback
from enum import Enum, unique

import networkx
import networkx as nx
from analysis.greedy_validation import check_execution_from_ids
from global_params.types import var_id_T, instr_id_T, instr_JSON_T, SMS_T

# Specific type to identify which positions corresponds to the ones
# in the current and final stacks
cstack_pos_T = int
fstack_pos_T = int

# Annotation for the maximum stack depth that can be managed through operations
STACK_DEPTH = 16


def _simplify_graph_to_selected_nodes(graph: nx.DiGraph, selected_nodes: List) -> nx.DiGraph:
    """
    Auxiliary method that returns the transitive reduction of the graph that is generated by
    preserving the initial paths in the original path when restricted to the selected nodes
    """
    subgraph = nx.DiGraph()
    subgraph.add_nodes_from(selected_nodes)

    # Add edges based on reachability using BFS/DFS
    for u in selected_nodes:
        for v in selected_nodes:
            # Avoid self-loops and skips relations that have already been considered
            if u != v and not subgraph.has_edge(v, u):

                # Check if v is reachable from u in G using DFS
                reachable = nx.algorithms.dfs_predecessors(graph, source=u)
                if v in reachable:
                    subgraph.add_edge(u, v)

    # Step 4: Apply transitive reduction on the dynamically created subgraph
    subgraph_reduced = nx.transitive_reduction(subgraph)
    return subgraph_reduced


def idx_wrt_cstack(idx: fstack_pos_T, cstack: List, fstack: List) -> cstack_pos_T:
    """
    Given a position w.r.t fstack, returns the corresponding position w.r.t cstack
    """
    return idx - len(fstack) + len(cstack)


def idx_wrt_fstack(idx: cstack_pos_T, cstack: List, fstack: List) -> fstack_pos_T:
    """
    Given a position w.r.t cstack, returns the corresponding position w.r.t fstack
    """
    return idx - len(cstack) + len(fstack)


def top_relative_position_to_fstack(cstack: List[var_id_T], fstack: List[var_id_T]) -> int:
    return idx_wrt_fstack(0, cstack, fstack)


def extract_idx_from_id(instr_id: str) -> int:
    return int(instr_id.split('_')[-1])


def cheap(instr: instr_JSON_T) -> bool:
    """
    Cheap computations are those who take one instruction (i.e. inpt_sk is empty)
    """
    return len(instr['inpt_sk']) == 0 and instr["inpt_sk"] <= 2


class SymbolicState:
    """
    A symbolic state includes a stack, and a dict indicating the number of total uses of each
    instruction
    """

    def __init__(self, stack: List[var_id_T]) -> None:
        self.stack: List[var_id_T] = stack

        # Var uses counts how many times the corresponding variables appears in the current stack
        self.var_uses: Dict[var_id_T, int] = self._computer_var_uses()

        self.debug_mode = True

    def _computer_var_uses(self):
        var_uses = defaultdict(lambda: 0)

        # Count vars in the initial stack
        for var_stack in self.stack:
            var_uses[var_stack] += 1

        return var_uses

    def swap(self, x: int) -> None:
        """
        Stores the top of the stack in the local with index x. in_position marks whether the element is
        solved in flocals
        """
        assert 0 <= x < len(self.stack), f"Swapping with index {x} a stack of {len(self.stack)} elements: {self.stack}"
        self.stack[0], self.stack[x] = self.stack[x], self.stack[0]

        # Var uses: no modification, as we are just moving two elements

    def dup(self, x: int) -> None:
        """
        Tee instruction in local with index x. in_position marks whether the element is solved in flocals
        """
        assert 0 <= x < len(self.stack), f"Duplicating index {x} in a stack in {len(self.stack)} elements: {self.stack}"
        self.stack.insert(0, self.stack[x])

        # Var uses: we increment the element that we have in its corresponding position
        self.var_uses[self.stack[0]] += 1

    def pop(self):
        """
        Drops the last element
        """
        stack_var = self.stack.pop(0)

        # Var uses: we subtract one because the stack var is totally removed from the encoding
        self.var_uses[stack_var] -= 1

    def uf(self, instr: instr_JSON_T):
        """
        Symbolic execution of instruction instr. Additionally, checks the arguments match if debug mode flag is enabled
        """
        consumed_elements = [self.stack.pop(0) for _ in range(len(instr['inpt_sk']))]

        # Neither liveness nor var uses are affected by consuming elements, as these elements are just being embedded
        # into a new term
        # Debug mode to check the pop args from the stack match
        if self.debug_mode:
            if instr['commutative']:
                # Compare them as multisets
                assert Counter(consumed_elements) == Counter(instr['inpt_sk']), \
                    f"{instr['id']} is not consuming the correct elements from the stack"
            else:
                # Compare them as lists
                assert consumed_elements == instr['inpt_sk'], \
                    f"{instr['id']} is not consuming the correct elements from the stack"

        # We introduce the new elements
        for output_var in instr['outpt_sk']:
            self.stack.insert(0, output_var)
            # Var uses: increase one for each generated stack var
            self.var_uses[output_var] += 1

        return instr['outpt_sk']

    def top_stack(self) -> Optional[var_id_T]:
        return None if len(self.stack) == 0 else self.stack[0]

    def __repr__(self):
        return str(self.stack)


class SMSgreedy:

    def __init__(self, json_format: SMS_T):
        self._user_instr: List[instr_JSON_T] = json_format['user_instrs']
        self._initial_stack: List[var_id_T] = json_format['src_ws']
        self._final_stack: List[var_id_T] = json_format['tgt_ws']
        self._vars: List[var_id_T] = json_format['vars']
        self._deps: List[Tuple[var_id_T, var_id_T]] = json_format['dependencies']
        self.debug_logger = DebugLogger()

        # Note: we assume function invocations might have several variables in 'outpt_sk'
        self._var2instr = {var: ins for ins in self._user_instr for var in ins['outpt_sk']}
        self._id2instr = {ins['id']: ins for ins in self._user_instr}
        self._var2id = {var: ins['id'] for ins in self._user_instr for var in ins['outpt_sk']}
        self._var2pos_stack = self._compute_var2pos(self._final_stack)

        self._var_total_uses = self._compute_var_total_uses()
        direct_g, indirect_g = self._compute_dependency_graph()

        self._relevant_ops = self.select_ops(direct_g)
        self._indirect_g = _simplify_graph_to_selected_nodes(indirect_g, self._relevant_ops)
        self._direct_g = _simplify_graph_to_selected_nodes(direct_g, self._relevant_ops)

        # We determine which elements must be computed in order to compute certain instruction
        self._values_used = {}
        for instr_id in self._relevant_ops:
            self._compute_values_used(self._id2instr[instr_id], self._relevant_ops, self._values_used)

        # Determine which topmost elements can be reused in the graph
        self._top_can_be_used = {}
        for instr in self._user_instr:
            self._compute_top_can_used(instr, self._top_can_be_used)

        # We need to compute the sub graph over the full dependency graph, as edges could be lost if we use the
        # transitive reduction instead. Hence, we need to compute the transitive_closure of the graph
        self._trans_sub_graph = nx.transitive_reduction(nx.DiGraph([*self._direct_g.edges, *self._indirect_g.edges]))
        for node in self._relevant_ops:
            self._trans_sub_graph.add_node(node)

    def _compute_var_total_uses(self) -> Dict[var_id_T, int]:
        """
        Computes how many times each var appears either in the final stack or as a subterm
        for other terms.
        """
        var_uses = defaultdict(lambda: 0)

        # Count vars in the final stack
        for var_stack in self._final_stack:
            var_uses[var_stack] += 1

        # Count vars as input of other instrs
        for instr_id, instr in self._id2instr.items():
            for subterm_var in instr['inpt_sk']:
                var_uses[subterm_var] += 1

        return var_uses

    def _compute_var2pos(self, var_list: List[var_id_T]) -> Dict[var_id_T, List[int]]:
        """
        Dict that links each stack variable that appears in a var list to the
        list of positions it occupies
        """
        var2pos = defaultdict(lambda: [])

        for i, stack_var in enumerate(var_list):
            var2pos[stack_var].append(i)

        return var2pos

    def _compute_dependency_graph(self) -> Tuple[nx.DiGraph, nx.DiGraph]:
        """
        We generate two dependency graphs: one for direct relations (i.e. one term embedded into another)
        and other with the dependencies due to memory/storage accesses
        """
        direct_graph = nx.DiGraph()
        indirect_graph = nx.DiGraph()

        for instr in self._user_instr:
            instr_id = instr['id']
            direct_graph.add_node(instr_id)
            indirect_graph.add_node(instr_id)

            for stack_elem in instr['inpt_sk']:
                # This means the stack element corresponds to another uninterpreted instruction
                if stack_elem in self._var2instr:
                    direct_graph.add_edge(self._var2id[stack_elem], instr_id)

        # We need to consider also the order given by the tuples
        for id1, id2 in self._deps:
            indirect_graph.add_edge(id1, id2)

        return direct_graph, indirect_graph

    def select_ops(self, direct_g: nx.DiGraph):
        """
        Selects which operations are considered in the algorithm. We consider mem operations (excluding loads with no
        dependencies) and computations that are not subterms
        """
        dep_ids = set(elem for dep in self._deps for elem in dep)

        # Relevant operations corresponds to memory operations (STORE in all cases, LOADs an KECCAKs if they have some
        # some kind of dependency) and operations that are not used elsewhere. The idea here is that we want
        # to consider the maximal elements to compute, as reusing computations is easier this way
        relevant_operations = [instr["id"] for instr in self._user_instr if
                               any(instr_name in instr["disasm"] for instr_name in ["STORE"])
                               or (any(load_instr in instr["disasm"] for load_instr in ["LOAD", "KECCAK"])
                                   and instr["id"] in dep_ids)
                               or direct_g.out_degree(instr["id"]) == 0]
        return relevant_operations

    def _compute_top_can_used(self, instr: instr_JSON_T, top_can_be_used: Dict[var_id_T, Set[var_id_T]]) -> Set[var_id_T]:
        """
        Computes for each instruction if the topmost element of the stack can be reused directly
        at some point. It considers commutative operations
        """
        reused_elements = top_can_be_used.get(instr["id"], None)
        if reused_elements is not None:
            return reused_elements

        current_uses = set()
        comm = instr["commutative"]
        first_element = True
        for stack_var in reversed(instr["inpt_sk"]):
            # We only consider the first element if the operation is not commutative, or both elements otherwise
            if comm or first_element:
                instr_bef = self._var2instr.get(stack_var, None)
                if instr_bef is not None:
                    instr_bef_id = instr_bef["id"]
                    if instr_bef_id not in top_can_be_used:
                        current_uses.update(self._compute_top_can_used(instr_bef, top_can_be_used))
                    else:
                        current_uses.update(top_can_be_used[instr_bef_id])
                    # Add only instructions that are relevant to our context
                    current_uses.add(stack_var)
            else:
                break
            first_element = False

        top_can_be_used[instr["id"]] = current_uses
        return current_uses

    def _compute_values_used(self, instr: instr_JSON_T, relevant_ops: List[instr_id_T],
                             value_uses: Dict[var_id_T, Set[var_id_T]]) -> Set[var_id_T]:
        """
        For a given instruction, determines which stack elements must be computed
        """
        values_used = value_uses.get(instr["id"], None)
        if values_used is not None:
            return values_used

        current_uses = set()
        for stack_var in instr["inpt_sk"]:
            instr_bef = self._var2instr.get(stack_var, None)
            if instr_bef is not None:
                instr_bef_id = instr_bef["id"]
                if instr_bef_id not in value_uses:
                    current_uses.update(self._compute_values_used(instr_bef, relevant_ops, value_uses))
                else:
                    current_uses.update(value_uses[instr_bef_id])
                # Add only instructions that are relevant to our context
                if instr_bef_id in relevant_ops:
                    current_uses.add(stack_var)
            else:
                current_uses.add(stack_var)
        value_uses[instr["id"]] = current_uses
        return current_uses

    def greedy(self) -> List[instr_id_T]:
        """
        Main implementation of the greedy algorithm (i.e. the instruction scheduling algorithm)
        """
        cstate: SymbolicState = SymbolicState(self._initial_stack)

        dep_graph = self._trans_sub_graph.copy()
        optg = []

        self.debug_logger.debug_initial(dep_graph.nodes)

        # For easier code, we end the while when we need to choose an
        # operation and there are no operations left
        while True:
            var_top = cstate.top_stack()

            self.debug_logger.debug_loop(dep_graph, optg, cstate)

            # Case 1: Top of the stack must be removed, as it appears more time it is being used
            if var_top is not None and cstate.var_uses[var_top] > self._var_total_uses[var_top]:
                self.debug_logger.debug_pop(var_top, cstate)
                cstate.pop()
                optg.append("POP")

            # Case 2: Top of the stack must be placed in some other position
            elif var_top is not None and self.var_must_be_moved(var_top, cstate):
                optg.extend(self.move_top_to_position(var_top, cstate))

            # Case 3: Top of the stack cannot be moved to the corresponding position.
            # Hence, we just generate the following computation
            else:
                # There are no operations left to choose, so we stop the search
                if len(dep_graph.nodes) == 0:
                    break

                next_id, location = self.choose_next_computation(cstate, dep_graph)
                self._debug_choose_computation(next_id, location, cstate)

                # It is already stored in a local
                if location == 'local':
                    # We just load the stack var
                    x = cstate.local_with_value(next_id)
                    cstate.lget(x)
                    ops = [f'LGET_{x}']
                elif location == 'cheap':
                    # Cheap instructions are just computed, there is no need to erase elements from the lists
                    ops = self.compute_instr(self._id2instr[next_id], cstate)
                else:
                    next_instr = self._id2instr[next_id]
                    # After choosing a value that must be computed, we store intermediate values that are used in locals
                    ops = self.store_needed_value(next_instr, cstate)
                    self._debug_store_intermediate(next_id, ops)

                    other_ops = self.compute_instr(next_instr, cstate)
                    self._debug_compute_instr(next_id, other_ops)
                    ops.extend(other_ops)
                    dep_graph.remove_node(next_id)

                optg.extend(ops)

        optg.extend(self.solve_permutation(cstate))
        self.debug_logger.debug_after_permutation(cstate, optg)

        return optg

    def _available_positions(self, var_elem: var_id_T, cstate: SymbolicState) -> Generator[cstack_pos_T]:
        """
        Generator for the set of available positions in cstack where the var element can be placed
        """
        # We just need to check that the positions in which the element appears in the
        # final stack are in range and not contain the element
        for position in reversed(self._var2pos_stack[var_elem]):
            fidx = idx_wrt_cstack(position, cstate.stack, self._final_stack)

            # When the index is negative, it means there are not enough elements in cstack
            # to place the corresponding element
            if fidx < 0:
                break

            # A variable must be moved when a positive index is found (less than STACK_DEPTH)
            # which does not contain yet the corresponding element
            elif STACK_DEPTH >= fidx >= 0 and cstate.stack[fidx] != var_elem:
                yield position

    def var_must_be_moved(self, var_elem: var_id_T, cstate: SymbolicState) -> bool:
        """
        By construction, a var element must be moved if there is an available position in which it
        appears in the final stack (and it is not yet in its position)
        """
        topmost_idx_fstack = idx_wrt_fstack(0, cstate.stack, self._final_stack)
        return (topmost_idx_fstack < 0 or self._final_stack[topmost_idx_fstack] != var_elem) and \
            next(self._available_positions(var_elem, cstate), None) is not None

    def move_top_to_position(self, var_elem: var_id_T, cstate: SymbolicState) -> List[instr_id_T]:
        """
        Stores the current element in all the positions in which it is available to be moved.
        """
        # TODO: decide if we just want to move one element or duplicate it as many
        #  times as it is possible
        # We just need to retrieve the deepest element
        deepest_position_available = next(self._available_positions(var_elem, cstate))

        cstate.swap(deepest_position_available)
        return [f"SWAP{deepest_position_available}"]

    def choose_next_computation(self, cstate: SymbolicState, dep_graph: networkx.DiGraph) -> instr_id_T:
        """
        Returns an element from mops, sops or lops and where it came from (mops, sops or lops)
        TODO: Here we should try to devise a good heuristics to select the terms
        """

        # To determine the best candidate to compute, we choose a variable among the ones that can be placed in
        # their position such that they can reuse a topmost element. If it is not possible,
        # we compute a memory element
        candidate = None
        min_unsolved = len(cstate.locals) + 1
        min_uses_top = False
        current_top = cstate.top_stack()

        # First we try to assign an element from the list of final local values if it can be placed in all the gaps
        # We also determine the element which has more
        candidates = [id_ for id_ in dep_graph.nodes if dep_graph.in_degree(id_) == 0]

        # First case: try to determine if there is an element (probably, LOAD or something) that is embedded into other
        # term and can be both applied
        for candidate in candidates:

            # Traverse all the operations that use it as a term
            direct_edges = self._direct_g.out_edges(candidate)
            for _, out_node in direct_edges:

                indirect_deps = [dep[0] for dep in dep_graph.in_edges(out_node)]

                if len(indirect_deps) == 0 or indirect_deps == [candidate]:
                    dep_graph.remove_node(candidate)
                    self._indirect_g.remove_node(candidate)
                    self._direct_g.remove_node(candidate)
                    return out_node

        for id_ in candidates:
            top_instr = self._id2instr[id_]

            # If there is an operation whose produced elements can be placed in all locals, we choose that element
            all_solved = True
            not_solved = len(cstate.locals) + 1

            # Call instructions might generate multiple values that we should take into account
            for out_var in top_instr['outpt_sk']:
                # TODO consider in locals that can be solved how the operation could liberate some local registers
                avail_solved_flocals = self._locals_that_can_be_solved(out_var, cstate)
                pos_flocals = self._var2pos_locals[out_var]

                # Current heuristics: select as a candidate the instruction with the most number of positions that
                # can be solved
                all_solved = all_solved and len(pos_flocals) == len(avail_solved_flocals)
                not_solved = min(not_solved, len(pos_flocals) - len(avail_solved_flocals))

            uses_top = current_top is not None and current_top in self._top_can_be_used[id_]

            if all_solved and uses_top:
                return id_, 'lops'
            # Condition: now it reuses top or solves more operations
            elif uses_top and (uses_top != min_uses_top or not_solved <= min_unsolved):
                candidate = id_
                min_uses_top = not_solved
                min_uses_top = uses_top

        if candidate is None:
            candidate = candidates[0]

        # Finally, we just choose an element from locals that covers multiple gaps,
        # which has been determined previously
        return candidate, 'lops'


class DebugLogger:

    """
    Class that contains the multiple debugging messages for the greedy algorithm
    """
    
    def __init__(self):
        self._logger = logging.Logger("greedy")
    
    def debug_initial(self, ops: List[instr_id_T]):
        self._logger.debug("---- Initial Ops ----")
        self._logger.debug(f'Ops:{ops}')
        self._logger.debug("")

    def debug_loop(self, dep_graph, optg: List[instr_id_T],
                    cstate: SymbolicState):
        self._logger.debug("---- While loop ----")
        self._logger.debug("Ops not computed", dep_graph.nodes)
        self._logger.debug("Ops computed", optg)
        self._logger.debug(cstate)
        self._logger.debug("")

    def debug_pop(self, var_top: var_id_T, cstate: SymbolicState):
        self._logger.debug("---- Drop term ----")
        self._logger.debug("Var Term", var_top)
        self._logger.debug('State', cstate)
        self._logger.debug("")

    def debug_after_permutation(self, cstate: SymbolicState, optg: List[instr_id_T]):
        self._logger.debug("---- State after solving permutation ----")
        self._logger.debug(cstate)
        self._logger.debug(optg)
        self._logger.debug("")
